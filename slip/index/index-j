#!/l/local/bin/perl

=head1 NAME

index-j

=head1 USAGE

% index-j -r run

=head1 DESCRIPTION

Take a slice of available items from the indexing queue, build docs for
the ids and send to Solr for indexing.  Record error ids in j_errors
table.  Record indexed status in j_indexed table.

Select the shard into which the item will be indexed by round-robin
scheduling.  If an item reappears later in the queue (rights changed,
etc.), consult the j_indexed table to select the correct shard for
re-indexing so the item does not get indexed in more than one shard.

The run number is associated with various experiments related to Solr
configuration and is used to compose the name of the config file. So
the config file for run number 1 would be
$SDRROOT/path-to-config-files/run-1.conf The config file points a solr
instance for each available shard.

Commit and optimize are manual processes or handled as part of the
driver_j process flow.

Protect shard from exceeding max shard size.  Co-operates with
sizer-j.  sizer-j will disable shard and re-enable shard to control
the flow of documents into a given shard.

=head1 OPTIONS

=over 8

=item -

see help

=back

=cut

use strict;
BEGIN {
    #$ENV{DEBUG_LOCAL} = 1;
}

# ----------------------------------------------------------------------
# Set up paths for local libraries -- must come first
# ----------------------------------------------------------------------
use lib "$ENV{SDRROOT}/mdp-lib/Utils";
use Vendors;


# Perl
use CGI;
use Getopt::Std;

# App
use Utils;
use Utils::Time;
use Debug::DUtils;

use Context;
use MdpConfig;
use Database;
use Search::Constants;
use Utils::GlobalSwitch;

# Lib
use Db;
use SLIP_Utils::Db_driver;
use SLIP_Utils::Common;
use SLIP_Utils::States;
use SLIP_Utils::Log;
use SLIP_Utils::YamlConfig;

use Index_Module;

my $INTERACTIVE = $ENV{TERM};

if ($INTERACTIVE) {
    if (Utils::GlobalSwitch::cron_jobs_disabled('slip', 'STOPSLIP')) {
        __output("Cannot index. STOPSLIP in place!!\n");
        exit 0;
    }
}
else {
    Utils::GlobalSwitch::Exit_If_cron_jobs_disabled('STOPSLIP');
}


# ---------------------------------------------------------------------

=item i_get_usage

Description

=cut

# ---------------------------------------------------------------------
sub i_get_usage {
    my $s .= qq{Usage: index-j -r run [-H host][-I id][-d 1|2|3][-v][-T]
            where -I id indexes one id
                  -H hostname overrides \`hostname\` call
                  -v turns on verbose logging
                  -d sets the debug level
                      where 1=default
                            2=add vufind + HTTP response 
                            3=add docfulldebug (no delete of zip tmpdir)\n};
    return $s;
}

# When total docs reaches an even multiple of the stop point the
# indexer stops.

our ($opt_d, $opt_r, $opt_I, $opt_H, $opt_v, $opt_T);

my $ops = getopts('d:r:I:vH:T');

my $VERBOSE_LOGGING = defined($opt_v);

if (defined($opt_d)) {
    if (! grep(/1|2|3/, ($opt_d))) {
        my $s = i_get_usage();
        __output($s);
        exit $SLIP_Utils::States::RC_BAD_ARGS;
    }

    $ENV{'DEBUG'} .= 'lsdb,idx,doc,me';
    $ENV{'DEBUG'} .= ',vufind'
        if ($opt_d == 2);
    $ENV{'DEBUG'} .= ',docfulldebug'
        if ($opt_d == 3);

    $VERBOSE_LOGGING = 1;
}

# Required
my $RUN = $opt_r;
my $PID = $$;
my $HOST = $opt_H;
if (! defined($HOST)) {
    $HOST = `hostname`; chomp($HOST); $HOST =~ s,\..*$,,;
}

if (! $opt_r) {
    my $s = i_get_usage();
    __output($s);
    exit $SLIP_Utils::States::RC_BAD_ARGS;
}

my $TEST_ONLY = defined($opt_T);
exit 0 if ($TEST_ONLY);

# Flush i/o
$| = 1;

my $C = new Context;

my $config = SLIP_Utils::Common::gen_run_config('slip', $RUN);
$C->set_object('MdpConfig', $config);

# put ns2label map on context object

my $ns_url = $config->get('namespace_mapping_url');
my $yaml_config = new SLIP_Utils::YamlConfig($ns_url);
$C->set_object('YamlConfig', $yaml_config);

my $db;
eval {
    $db = new Database($config);
};
if ($@) {
    SLIP_Utils::Common::Log_database_connection_error($C, 'index-j', $@);
    exit $SLIP_Utils::States::RC_DATABASE_CONNECT;
}

$C->set_object('Database', $db);

my $DBH = $db->get_DBH();

my $DEFAULT_SLICE_SIZE = $config->get('queue_slice_size');

# Index just one id
my $SINGLE_ID = $opt_I;

my $GLOBAL_ref_to_ary_of_id_hashref = [];
my $GLOBAL_ref_to_ary_of_id_error_recovery_hashref = [];

my $PROCESSING = 1;
eval {
    i_processing_loop($C);
};
if ($@) {
    # Place remaining ids on the error list, disable the shard that had
    # the error and log it.
    handle_critical_error($C, $DBH, $RUN, Index_Module::get_GLOBAL_error_shard(), $PID, $HOST, $@);
    # NOTREACHED
}

exit Index_Module::get_MAX_ERRORS_SEEN();

#
# ---------------------  Main  S u b r o u t i n e s   -------------------------
#


# ---------------------------------------------------------------------

=item i_processing_loop

Description

=cut

# ---------------------------------------------------------------------
sub i_processing_loop {
    my $C = shift;

    my $item_ct = 0;
    my $slices_taken = 0;

    while ($PROCESSING) {
        # Exit this producer if the stop file is touched
        Utils::GlobalSwitch::Exit_If_cron_jobs_disabled('STOPSLIP');
        # POSSIBLY NOTREACHED

        # Exit before (another) slice is taken if this host is
        # disabled
        handle_host_enabled($C, $DBH, $RUN, $PID, $HOST, $slices_taken);
        # POSSIBLY NOTREACHED

        # Exit this producer if time of day falls between the downtime
        # for VuFind Solr. We need VuFind for Solr document metadata.
        handle_vSolr_downtime($C);
        # POSSIBLY NOTREACHED

        # Exit this producer before (another) slice is taken and
        # marked as available for indexing if max configured producers
        # are running
        handle_max_producers_running($C, $DBH, $RUN, $HOST);
        # POSSIBLY NOTREACHED

        # Exit if no shards are enabled to receive data
        handle_indexer_pool($C, $DBH, $RUN, $PID, $HOST, $slices_taken);
        # POSSIBLY NOTREACHED

        # OK to proceed: get a slice of ids from the queue or just one
        # id and save in the GLOBAL error recovery id array
        my $num_ids = Read_indexing_queue($C);

        # Exit if the queue is empty
        handle_queue_empty($C, $RUN, $PID, $HOST, $num_ids);
        # POSSIBLY NOTREACHED

        $slices_taken++;

        # Logging
        handle_startup($C, $DBH, $RUN, $PID, $HOST, $slices_taken, $num_ids);

        # Go to work
        while (my $hashref = get_id_from_slice()) {
            my $id = $hashref->{'id'};
            $item_ct++;

            Index_Module::Service_ID($C, $DBH, $RUN, $PID, $HOST, $id, $item_ct);

            remove_id_from_backup_list();

            # Remove item from the input queue. Critical errors (9)
            # cause a longjump out of i_processing_loop() and add IDs
            # to j_errors and deletes them from j_queue atomically
            # without resorting to a call to handle_dequeue().
            handle_dequeue($C, $DBH, $RUN, $id, $PID, $HOST);
        }
    }
}

#
# --------------- Helper  S u b r o u t i n e s   @@-------------------
#

# ---------------------------------------------------------------------

=item get_id_from_slice

Description

=cut

# ---------------------------------------------------------------------
sub get_id_from_slice {
    my $item_hashref = shift @$GLOBAL_ref_to_ary_of_id_hashref;
    return $item_hashref;
}

# ---------------------------------------------------------------------

=item remove_id_from_backup_list

Description

=cut

# ---------------------------------------------------------------------
sub remove_id_from_backup_list {
    my $id = shift @$GLOBAL_ref_to_ary_of_id_error_recovery_hashref;
}

# ---------------------------------------------------------------------

=item Read_indexing_queue

-I ($SINGLE_ID) NOT intended to run from a cron job

=cut

# ---------------------------------------------------------------------
sub Read_indexing_queue {
    my $C = shift;

    if ($SINGLE_ID) {
        my %item_hash = (
                         'id' => $SINGLE_ID,
                        );
        $GLOBAL_ref_to_ary_of_id_hashref = [\%item_hash];
        $PROCESSING = 0;
    }
    else {
        $GLOBAL_ref_to_ary_of_id_hashref =
            Db::Select_id_slice_from_queue($C, $DBH, $RUN, $PID, $HOST, $DEFAULT_SLICE_SIZE);

        # Put contents of @$GLOBAL_ref_to_ary_of_id_hashref back into
        # queue if critical error or lack of indexers leaves sliced
        # items unprocessed.
        push(@$GLOBAL_ref_to_ary_of_id_error_recovery_hashref,
             @$GLOBAL_ref_to_ary_of_id_hashref);
    }

    return scalar(@$GLOBAL_ref_to_ary_of_id_hashref);
}


#
# --------------- Handling  S u b r o u t i n e s   @@-------------------
#

# ---------------------------------------------------------------------

=item handle_vSolr_downtime

Description

=cut

# ---------------------------------------------------------------------
sub handle_vSolr_downtime {
    my $C = shift;
    my $config = $C->get_object('MdpConfig');

    return
        if (! $config->get('vSolr_downtime_checking'));

    my @downtime = $config->get('vSolr_downtime_interval');

    my ($second, $minute, $hour) = localtime();
    my $decimal_hour = $hour + $minute/60.0;

    if (
        ($decimal_hour > $downtime[0])
        &&
        ($decimal_hour < $downtime[1])
       ) {
        exit 0;
    }
}


# ---------------------------------------------------------------------

=item handle_max_producers_running

Description

=cut

# ---------------------------------------------------------------------
sub handle_max_producers_running {
    my ($C, $dbh, $run, $host) = @_;

    my ($max_running, $num_configured, $num_running) =
        SLIP_Utils::Common::max_producers_running($C, $dbh, $run, $host);

    if ($max_running && ($num_running-1 > 0)) {
        Log_max_producers_seen($C, $run, $PID, $host, $num_configured, $num_running-1);
        DEBUG('me', qq{DEBUG: max producers running ... exit});
        exit 0;
    }
}

# ---------------------------------------------------------------------

=item handle_startup

Description

=cut

# ---------------------------------------------------------------------
sub handle_startup {
    my ($C, $dbh, $run, $pid, $host, $slices_taken, $num_ids) = @_;

    # Log first time through slice-taking loop
    if ($slices_taken == 1) {
        Log_startup($C, $run, $pid, $host);
        DEBUG('me', qq{DEBUG: startup});
    }

    Log_slice($C, $run, $pid, $host, $num_ids);
    DEBUG('me', qq{DEBUG: process slice num=$num_ids});
}


# ---------------------------------------------------------------------

=item handle_host_enabled

Description

=cut

# ---------------------------------------------------------------------
sub handle_host_enabled {
    my ($C, $dbh, $run, $pid, $host, $work_done) = @_;

    my $host_enabled = Db::Select_host_enabled($C, $dbh, $run, $host);

    if (! $host_enabled) {
        Log_host_Shutdown($C, $run, $pid, $host)
            if ($work_done);
        DEBUG('me', qq{DEBUG: host=$host stop requested, slices taken=$work_done ... exit});
        exit 0;
    }
}


# ---------------------------------------------------------------------

=item handle_indexer_pool

Description

=cut

# ---------------------------------------------------------------------
sub handle_indexer_pool {
    my ($C, $dbh, $run, $pid, $host, $work_done) = @_;

    my $num_indexers_available = 
      Index_Module::get_INDEXER_POOL($C, $dbh, $run)->get_num_indexers_available($C);

    if ($num_indexers_available == 0)
    {
        Log_shard_Shutdown($C, $run, $pid, $host)
            if ($work_done);
        DEBUG('me', qq{DEBUG: no unsuspended shards enabled, host=$host slices taken=$work_done ... exit});
        exit 0;
    }
}

# ---------------------------------------------------------------------

=item handle_dequeue

Description

=cut

# ---------------------------------------------------------------------
sub handle_dequeue {
    my ($C, $dbh, $run, $id, $pid, $host) = @_;

    Db::dequeue($C, $dbh, $run, $id, $pid, $host);
    Log_dequeue($C, $run, $id, $pid, $host);
}

# ---------------------------------------------------------------------

=item handle_queue_empty

Description

=cut

# ---------------------------------------------------------------------
sub handle_queue_empty {
    my ($C, $run, $pid, $host, $num_sliced_from_queue) = @_;

    if ($num_sliced_from_queue == 0) {
        Log_queue_empty($C, $run, $pid, $host);
        DEBUG('me', qq{DEBUG: queue empty ... exit});
        exit 0;
    }
}


# ---------------------------------------------------------------------

=item handle_critical_error

Description

=cut

# ---------------------------------------------------------------------
sub handle_critical_error {
    my ($C, $dbh, $run, $shard, $pid, $host, $error) = @_;

    # Have we lost the database?
    my $connection_still_alive = $dbh->ping();
    if ($connection_still_alive) {
        Db::set_shard_build_error($C, $dbh, $run, $shard)
                if (! $INTERACTIVE);

        # Un-handled ids are in the GLOBAL error array. Put them in
        # the error list and disable the shard.
        while (my $item_hashref = shift @$GLOBAL_ref_to_ary_of_id_error_recovery_hashref) {
            my $id = $item_hashref->{'id'};
            Db::insert_item_id_error($C, $dbh, $run, $shard, $id, $pid, $host, IX_CRITICAL_FAILURE);
        }
        # Turn off this shard.
        Db::update_shard_enabled($C, $dbh, $run, $shard, 0);
    }
    else {
        # No database to talk to.  Save the ids in an error log file
        # and restore them to j_queue, later, by hand.
        while (my $item_hashref = shift @$GLOBAL_ref_to_ary_of_id_error_recovery_hashref) {
            my $id = $item_hashref->{'id'};
            Log_critical($C, $run, $id);
        }
    }

    my $subj = qq{[SLIP] CRITICAL ERROR: run=$run shard=$shard};
    my $msg =
        qq{CRITICAL ERROR } .
            qq{run=$run shard=$shard pid=$pid host=$host\nerror=$error\n};
    $msg .= qq{database connection lost\nunprocessed restorable ids logged in file=logs/___DATE___/run-$run/critical_ids___PID___.log\n}
        if (! $connection_still_alive);
    SLIP_Utils::Common::Send_email($C, 'report', $subj, $msg);

    Index_Module::Log_error_stop($C, $run, $shard, $pid, $host, qq{CRITICAL ERROR: $error});

    my $rc = $SLIP_Utils::States::RC_CRITICAL_ERROR;

    __output($msg);
    __non_interactive_err_output($rc, $msg);

    exit $rc;
}



#
# --------------------- Logging  S u b r o u t i n e s   @@-------------------------
#

# ---------------------------------------------------------------------

=item Log_critical

Description

=cut

# ---------------------------------------------------------------------
sub Log_critical {
    my ($C, $run, $id) = @_;

    my $s = Utils::Time::iso_Time() . qq{ id=$id};
    SLIP_Utils::Log::this_string($C, $s, 'critical_ids_logfile', '___RUN___', $run);
}

# ---------------------------------------------------------------------

=item Log_dequeue

Description

=cut

# ---------------------------------------------------------------------
sub Log_dequeue {
    my ($C, $run, $id, $pid, $host) = @_;

    my $s = qq{***DEQUEUE: } . Utils::Time::iso_Time() . qq{ id=$id r=$run pid=$pid h=$host};
    SLIP_Utils::Log::this_string($C, $s, 'indexer_logfile', '___RUN___', $run)
            if ($VERBOSE_LOGGING);
}

# ---------------------------------------------------------------------

=item Log_slice

Description; Procdeural interface

=cut

# ---------------------------------------------------------------------
sub Log_slice {
    my ($C, $run, $pid, $host, $num_sliced_from_queue) = @_;

    my $s = qq{***SLICE: } . Utils::Time::iso_Time() . qq{ r=$run pid=$pid h=$host slice_size=$num_sliced_from_queue};
    SLIP_Utils::Log::this_string($C, $s, 'indexer_logfile', '___RUN___', $run)
            if ($VERBOSE_LOGGING);
}

# ---------------------------------------------------------------------

=item Log_queue_empty

Description; Procdeural interface

=cut

# ---------------------------------------------------------------------
sub Log_queue_empty {
    my ($C, $run, $pid, $host) = @_;

    my $s = qq{***QUEUE EMPTY (exit): } . Utils::Time::iso_Time() . qq{ r=$run pid=$pid h=$host};
    SLIP_Utils::Log::this_string($C, $s, 'indexer_logfile', '___RUN___', $run)
            if ($VERBOSE_LOGGING);
}

# ---------------------------------------------------------------------

=item Log_startup

Description; Procdeural interface

=cut

# ---------------------------------------------------------------------
sub Log_startup {
    my ($C, $run, $pid, $host) = @_;

    my $s = qq{***START: } . Utils::Time::iso_Time() . qq{ r=$run pid=$pid h=$host};
    SLIP_Utils::Log::this_string($C, $s, 'indexer_logfile', '___RUN___', $run);
}


# ---------------------------------------------------------------------

=item Log_host_Shutdown

Description

=cut

# ---------------------------------------------------------------------
sub Log_host_Shutdown {
    my ($C, $run, $pid, $host) = @_;

    my $s = qq{***STOP (host): } . Utils::Time::iso_Time() . qq{ r=$run pid=$pid h=$host};
    SLIP_Utils::Log::this_string($C, $s, 'indexer_logfile', '___RUN___', $run);
}

# ---------------------------------------------------------------------

=item Log_shard_Shutdown

Description

=cut

# ---------------------------------------------------------------------
sub Log_shard_Shutdown {
    my ($C, $run, $pid, $host) = @_;

    my $s = qq{***STOP (no shards): } . Utils::Time::iso_Time() . qq{ r=$run pid=$pid h=$host};
    SLIP_Utils::Log::this_string($C, $s, 'indexer_logfile', '___RUN___', $run);
}

# ---------------------------------------------------------------------

=item Log_max_producers_seen

Description

=cut

# ---------------------------------------------------------------------
sub Log_max_producers_seen {
    my ($C, $run, $pid, $host, $num_configured, $num_running) = @_;

    my $s = qq{***MAX PRODUCERS (exit): } 
      . Utils::Time::iso_Time() 
        . qq{ r=$run pid=$pid h=$host num_cfgd=$num_configured num_running=$num_running};
    SLIP_Utils::Log::this_string($C, $s, 'indexer_logfile', '___RUN___', $run)
            if ($VERBOSE_LOGGING);
}

1;


=head1 AUTHOR

Phillip Farber, University of Michigan, pfarber@umich.edu

=head1 COPYRIGHT

Copyright 2008-11 ©, The Regents of The University of Michigan, All Rights Reserved

Permission is hereby granted, free of charge, to any person obtaining
a copy of this software and associated documentation files (the
"Software"), to deal in the Software without restriction, including
without limitation the rights to use, copy, modify, merge, publish,
distribute, sublicense, and/or sell copies of the Software, and to
permit persons to whom the Software is furnished to do so, subject
to the following conditions:

The above copyright notice and this permission notice shall be
included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY
CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE
SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

=cut
