#!/usr/bin/env perl

=head1 NAME

sync-i

=head1 USAGE

% sync-i -r run [-C coll_id] [-s <slice_size>][-d][-n][-q][-P 1|2]

=head1 DESCRIPTION

Synchronize the LS index with the CB database tables.

=head1 OPTIONS

=cut

use strict;

# ----------------------------------------------------------------------
# Set up paths for local libraries -- must come first
# ----------------------------------------------------------------------
use lib "$ENV{SDRROOT}/mdp-lib/Utils";
use Vendors;

# Perl
use Getopt::Std;

# App
use Utils;
use Utils::Time;
use Utils::GlobalSwitch;
use Debug::DUtils;

use Context;
use MdpConfig;
use Identifier;
use SharedQueue;
use RightsGlobals;

use Search::Searcher;
use Search::Result::SLIP;
use SLIP_Utils::Common;
use SLIP_Utils::Solr;
use SLIP_Utils::Released;
use SLIP_Utils::DatabaseWrapper;
use Db;

use Collection;
use CollectionSet;


my $INTERACTIVE = $ENV{TERM};
if ($INTERACTIVE) {
    if (Utils::GlobalSwitch::cron_jobs_disabled('slip')) {
        l__output("Cannot sync. STOPSLIP in place!!\n");
        exit 0;
    }
}
else {
    Utils::GlobalSwitch::Exit_If_cron_jobs_disabled('slip');
}

# ---------------------------------------------------------------------

=item sync_get_usage

Description

=cut

# ---------------------------------------------------------------------
sub sync_get_usage {
    my $s .= qq{Usage: sync-i [-L][-C LARGE_coll_id] [-s <slice_size>][-d][-n][-P 1|2]
                  where the collection Builder tables are synched vs. the run-11 (production) index
                        -L L)ive otherwise print this message
                        -s is slice size of Solr and Mysql id query
                        -P run only phase 1 or 2
                        -C just do one LARGE coll_id
                        -n ids are not queued, just reported\n};
    return $s;
}

our ($opt_s, $opt_d, $opt_n, $opt_T, $opt_P, $opt_C, $opt_L);

my $ops = getopts('s:dnTqP:C:L');

my $RUN = 11;

use constant DEFAULT_SLICE_SIZE => 10000;
my $SLICE_SIZE = defined($opt_s) ? $opt_s : DEFAULT_SLICE_SIZE; # optional

if (defined($opt_d)) {
    $ENV{'DEBUG'} .= 'lsdb,idx,doc,me';
}

my $MESSAGE_BUFFER = '';
my $HOST = `hostname`;
$HOST =~ s,\..*$,,s;

my $COLL_ID = $opt_C; # optional
my $NOOP = defined($opt_n); # optional
my $PHASE = $opt_P;

my $TEST_ONLY = defined($opt_T);
exit 0 if ($TEST_ONLY);

my $LIVE = defined($opt_L);
unless ($LIVE) {
    print sync_get_usage();
    exit 0;
}

# Flush i/o
$| = 1;

my $C = new Context;
my $config = SLIP_Utils::Common::gen_SLIP_config($RUN);
$C->set_object('MdpConfig', $config);

my $production_run = $config->get('run_allowed_to_access_shared_queue');
if ($RUN ne $production_run) {
    my $rc = $SLIP_Utils::States::RC_BAD_ARGS;
    my $s = qq{run=$RUN NOT the production_run ($production_run)};
    l__output($C, $s, 1, 1, 1);
    __non_interactive_err_output($rc, $s);
    exit $rc;
}

my $DBH = SLIP_Utils::DatabaseWrapper::GetDatabaseConnection($C, 'sync-i');

my $CO = new Collection($DBH, $config, undef);
my $CS = new CollectionSet($DBH, $config, undef);
my @num_shards_list = $config->get('num_shards_list');
my @SHARDS = (@num_shards_list);

my $PROCESS_START = time();

eval {
    # Only sync with solr index if it is "new", i.e. if released for
    # today. Otherwise, we would see missing ids in yesterday's index
    my ($index_released, $r_msg) = SLIP_Utils::Released::released();
    l__output($C, "\n$r_msg on $HOST\n", 1, 1, 1);

    if ($index_released) {
        do_Sync($C, $PHASE);
    }
    else {
        if ($INTERACTIVE) {
            unless ($NOOP) {
                l__output($C, "Proceeding to queue today's IDs early\n", 1, 1, 1);
            }
            do_Sync($C, $PHASE);
        }
        else {
            l__output($C, "$r_msg Skipping sync-i run\n", 1, 1, 1);
        }
    }

    sy_final_report($C, $DBH);
};
if ($@) {
    my $rc = $SLIP_Utils::States::RC_CRITICAL_ERROR;
    my $s = qq{CRITICAL ERROR: sync-i: $@\n};
    l__output($C, $s, 1, 1, 1);
    __non_interactive_err_output($rc, $s);
    exit $rc;
}

exit 0;

#
# --------------------- S u b r o t i n e s   -------------------------
#

# ---------------------------------------------------------------------

=item do_Sync

Description

=cut

# ---------------------------------------------------------------------
sub do_Sync {
    my $C = shift;
    my $phase = shift;

    if ($phase) {
        handle_synchronization($C) if ($phase == 1);
        handle_inverse_synchronization($C) if ($phase == 2);
    }
    else {
        handle_synchronization($C);
        handle_inverse_synchronization($C);
    }
}

# ---------------------------------------------------------------------

=item Log_sync_i

Description

=cut

# ---------------------------------------------------------------------
sub Log_sync_i {
    my ($C, $run, $s) = @_;

    $s =~ s,\n, ,g;
    my $ss = qq{***UPDATE: } . Utils::Time::iso_Time() . qq{ run=$run $s};
    SLIP_Utils::Log::this_string($C, $ss, 'sync-i_logfile', '___RUN___', $run);
}

# ---------------------------------------------------------------------

=item sy_final_report

Description

=cut

# ---------------------------------------------------------------------
sub sy_final_report {
    my ($C, $dbh) = @_;

    my $process_elapsed = time() - $PROCESS_START;
    my $process_elapsed_min = sprintf("%.2f", $process_elapsed/60);

    my $s = qq{\nsync-i update: elapsed minutes=$process_elapsed_min\n};
    l__output($C, $s . Utils::Time::iso_Time() . qq{\n}, 1, 1, 1);
    $s .= $MESSAGE_BUFFER;
    $s =~ s,\n\n,\n,gs;

    my $subj = qq{[SLIP] sync-i report ($HOST)};
    SLIP_Utils::Common::Send_email($C, 'report', $subj, $s);
}

# ---------------------------------------------------------------------

=item __handle_query

Description

=cut

# ---------------------------------------------------------------------
sub __handle_query {
    my ($C, $query, $searcher, $rs) = @_;

    $rs = $searcher->get_Solr_raw_internal_query_result($C, $query, $rs);
    if (! $rs->http_status_ok()) {
        my $status = $rs->get_status_line();
        my $dump = $rs->get_failed_HTTP_dump();
        my $s = qq{Solr query=$query failed: \n$dump\n};
        l__output($C, $s, 1, 1, 1);
        __handle_rc($SLIP_Utils::States::RC_CRITICAL_ERROR, $s);
        # NOTREACHED
    }

    return $rs;
}

# ---------------------------------------------------------------------

=item __handle_rc

Description

=cut

# ---------------------------------------------------------------------
sub __handle_rc {
    my ($rc, $msg) = @_;

    if ($rc > 0) {
        l__output($C, qq{$msg\nError exit\n}, 1, 1, 1);
        __non_interactive_err_output($rc, $msg);
        exit $rc;
    }
}


# ---------------------------------------------------------------------

=item __id_exists

Description

=cut

# ---------------------------------------------------------------------
sub __id_exists {
    my ($C, $coll_id, $id, $searcher, $rs, $deleted_ref) = @_;

    my $safe_id = Identifier::get_safe_Solr_id($id);
    my $query = qq{q=id:$safe_id&start=0&rows=0};
    $rs = __handle_query($C, $query, $searcher, $rs);

    my $num_found = $rs->get_num_found();

    if ($num_found == 0) {
        # Was it "nobody"?
        my ($namespace, $barcode) = Identifier::split_id($id);
        my $rights_hashref = Db::Select_latest_rights_row($C, $DBH, $namespace, $barcode);
        my $attr = $rights_hashref->{attr};
        if ($attr == $RightsGlobals::g_available_to_no_one_attribute_value) {
            $$deleted_ref++;
        }
        l__output($C, qq{\nID=$id in coll_id=$coll_id does not exist in Solr\n}, 1, 0, 1);
    }

    return ($num_found > 0);
}

# ---------------------------------------------------------------------

=item __exit_STOPSLIP

Description

=cut

# ---------------------------------------------------------------------
sub __exit_STOPSLIP {

    if (Utils::GlobalSwitch::cron_jobs_disabled('slip')) {
        l__output($C, "exit STOPSLIP in place\n", 1, 1, 1);
        exit 0;
    }
}

# ---------------------------------------------------------------------

=item __coll_id_exists

Description

=cut

# ---------------------------------------------------------------------
sub __coll_id_exists {
    my ($C, $coll_id, $id, $searcher, $rs) = @_;

    my $safe_id = Identifier::get_safe_Solr_id($id);
    my $query = qq{q=coll_id:$coll_id+AND+id:$safe_id&start=0&rows=0};
    $rs = __handle_query($C, $query, $searcher, $rs);

    my $num_found = $rs->get_num_found();
    if ($num_found == 0) {
        l__output($C, qq{\nID=$id in Solr missing coll_id=$coll_id field. Enqueue unless NOOP.\n}, 1, 1, 1);
    }

    return ($num_found > 0);
}

# ---------------------------------------------------------------------

=item handle_synchronization

For a LARGE coll_id, test for every ID in the Collection:

1) ID exists in a Solr doc, i.e. is indexed
2) and, if so, that coll_id is a field value in the ID's Solr doc

IDs not in Solr, must have been deleted from the index so they are
orphaned from the Collection so we nothing by policy (Collection
Builder UI informs user some items are gone from the Solr index),
otherwise enqueue ID for Solr doc that lacks coll_id.

=cut

# ---------------------------------------------------------------------
sub handle_synchronization {
    my $C = shift;

    my $phase_1_start = time();

    l__output($C, qq{\n***\n*** Begin Phase I synchronization ... if ID in large coll then large coll coll_id is in Solr doc for that ID ...\n***\n\n}, 1, 1, 1);

    my $initial_shared_queue_ct = SharedQueue::count_shared_queue_ids($C, $DBH);
    l__output($C, qq{Initial shared queue count=$initial_shared_queue_ct\n}, 1, 1, 1);

    my $engine_uri = Search::Searcher::get_random_shard_solr_engine_uri($C);
    my $searcher = new Search::Searcher($engine_uri, undef, 1);
    my $rs = new Result::SLIP();

    my ($ok, $coll_id_arr_ref);
    if ($COLL_ID) {
        ($ok, $coll_id_arr_ref) = (1, [$COLL_ID]);
    }
    else {
        ($ok, $coll_id_arr_ref) = SharedQueue::get_large_coll_coll_ids($C, $DBH);
    }
    __handle_rc($ok ? $SLIP_Utils::States::RC_OK : $SLIP_Utils::States::RC_CRITICAL_ERROR,
                qq{Failed to get large coll_ids\n});

    my $s;
    my $ct = 0;
    my $coll_ct = 0;
    my $ids_in_colls = 0;
    my $missing_ids_over_colls = 0;

    foreach my $coll_id (@$coll_id_arr_ref) {

        __exit_STOPSLIP();

        $coll_ct++;
        my $num_ignored_as_deleted = 0;
        my $ids_missing_in_Solr = 0;
        my $coll_id_missing_in_Solr = 0;

        my $coll_name = $CO->get_coll_name($coll_id);
        my $id_arr_ref = $CO->get_ids_for_coll($coll_id);
        my $num_ids_in_coll = scalar(@$id_arr_ref);
        l__output($C, qq{\nProcessing IDs in coll_id=$coll_id ($coll_name) (num in coll=$num_ids_in_coll) for missing coll_id fields in Solr\n}, 1, 1, 1);

        $ids_in_colls += $num_ids_in_coll;

        my $id_ct = 0;
        foreach my $id (@$id_arr_ref) {

            __exit_STOPSLIP();

            $id_ct++;
            if (__id_exists($C, $coll_id, $id, $searcher, $rs, \$num_ignored_as_deleted)) {
                # Does its Solr doc contain this coll_id?
                unless ( __coll_id_exists($C, $coll_id, $id, $searcher, $rs) ) {
                    if (! $NOOP) {
                        $ok = SharedQueue::enqueue_item_ids($C, $DBH, [$id]);
                        __handle_rc($ok ? $SLIP_Utils::States::RC_OK : $SLIP_Utils::States::RC_CRITICAL_ERROR,
                                    qq{Failed to enqueue id=$id for coll_id=$coll_id\n});
                    }
                }
                else {
                   $coll_id_missing_in_Solr++;
                }
            }
            else {
                $ids_missing_in_Solr++;
                $missing_ids_over_colls++;
            }

            if (($id_ct % 100) == 0) {
                l__output($C, "($id_ct)", 1);
                # throttle solr requests to prevent 500's
                # sleep 1;
                l__output($C, '.', 1);
            }
        }

        $s = $ids_missing_in_Solr
          ? qq{\n\tcollid=$coll_id ($coll_name) [num in coll=$num_ids_in_coll] has $ids_missing_in_Solr IDs missing in Solr and  \n}
            : qq{\n\tAll Solr ids present for coll_id=$coll_id ($coll_name) [num in coll=$num_ids_in_coll]\n};
        my $ig = qq{\tnum ignored due to Deletes=$num_ignored_as_deleted\n};

        l__output($C, qq{$s$ig\n}, 1, 1, 1);
    }

    my $total_ids_queued = SharedQueue::count_shared_queue_ids($C, $DBH) - $initial_shared_queue_ct;
    $s = $NOOP ? '' : ", $total_ids_queued added to shared queue";
    my $ss = qq{\nPhase I processed MySQL large coll_ids=$coll_ct items=$ids_in_colls\n\t missing in Solr over all colls=$missing_ids_over_colls$s\n};
    l__output($C, $ss, 1, 1, 1);

    my $phase_1_elapsed = time() - $phase_1_start;
    my $elapsed_min = sprintf("%.2f", $phase_1_elapsed/60);
    $ss = qq{\nelapsed minutes=$elapsed_min\n};
    l__output($C, $ss, 1, 1, 1);
}

# ---------------------------------------------------------------------

=item __parse_result_docs

Description

=cut

# ---------------------------------------------------------------------
sub __parse_result_docs {
    my (
        $C, $rs, $large_coll_id_arr_ref,
        $missing_coll_ids_hashref,
        $small_coll_ids_hashref
       ) = @_;

    my %id_to_coll_id_hash = ();

    my %local_small_ids_to_enqueue = ();
    my %local_missing_ids_to_enqueue = ();

    my $ret_to_arr_of_hashref = $rs->get_complete_result();
    foreach my $hashref (@$ret_to_arr_of_hashref) {
        my $coll_ids_arr_ref = [];
        if ($COLL_ID) {
            $coll_ids_arr_ref = [$COLL_ID];
        }
        else {
            $coll_ids_arr_ref = $hashref->{coll_ids};
        }
        my $id = $hashref->{id};

        $id_to_coll_id_hash{$id} = $coll_ids_arr_ref;
    }

    # Optimization: If any of the coll_ids don't exist or are a
    # coll_id that is not "large", add the id to the "to be
    # re-indexed" list so we don't have to query MySQL redundantly for
    # every id that's in a non-existent or non-large collection.
    foreach my $id (keys %id_to_coll_id_hash) {
        foreach my $coll_id (@{ $id_to_coll_id_hash{$id} }) {
            if ($small_coll_ids_hashref->{$coll_id}) {
                $local_small_ids_to_enqueue{$id} = 1;
            }
            elsif ($missing_coll_ids_hashref->{$coll_id}) {
                $local_missing_ids_to_enqueue{$id} = 1;
            }
            elsif (! $CS->exists_coll_id($coll_id)) {
                $missing_coll_ids_hashref->{$coll_id} = 1;
                $local_missing_ids_to_enqueue{$id} = 1;
                l__output($C, qq{\n\tSolr doc w/id=$id has coll_id=$coll_id MISSING from MySQL }, 1, 0, 1);
            }
            elsif (! grep(/^$coll_id$/, @$large_coll_id_arr_ref)) {
                $small_coll_ids_hashref->{$coll_id} = 1;
                $local_small_ids_to_enqueue{$id} = 1;
                l__output($C, qq{\n\tSolr doc w/id=$id has coll_id=$coll_id that is NOT LARGE in MySQL }, 1, 0, 1);
            }
        }
    }

    foreach my $id (keys %local_missing_ids_to_enqueue) {
        delete $id_to_coll_id_hash{$id};
    }
    foreach my $id (keys %local_missing_ids_to_enqueue) {
        delete $id_to_coll_id_hash{$id};
    }

    my @small_ids_to_enqueue = keys %local_small_ids_to_enqueue;
    my @missing_ids_to_enqueue = keys %local_missing_ids_to_enqueue;

    return (\%id_to_coll_id_hash, \@small_ids_to_enqueue, \@missing_ids_to_enqueue);
}


# ---------------------------------------------------------------------

=item handle_inverse_synchronization

We now know that for every ID in a large coll_id that is in Solr, the
ID's Solr doc has the coll_id field.

Check that the ID of every Solr doc that has collection coll_id fields
are in those collections.  If not, the ID must have been deleted from
the collection but the ID somehow was not reindexed to remove the
coll_id field for the collection it's not longer a member of.

Enqueue the id for re-indexing so it will acquire the correct list of
coll_ids, sans the coll_id it was deleted from.

=cut

# ---------------------------------------------------------------------
sub handle_inverse_synchronization {
    my $C = shift;

    my $phase_2_start = time();

    l__output($C, qq{\n***\n*** Begin Phase II synchronization ... if Solr doc has a coll_id then the Solr doc ID is in MySQL collection with that coll_id\n***\n\n}, 1, 1, 1);

    my $initial_shared_queue_ct = SharedQueue::count_shared_queue_ids($C, $DBH);
    l__output($C, qq{Initial shared queue count=$initial_shared_queue_ct\n}, 1, 1, 1);

    my $num_ids_from_missing_coll_ids = 0;
    my $num_ids_from_small_coll_ids = 0;

    my $total_ids_queued_over_shards = 0;
    my $total_ids_processed_over_shards = 0;

    foreach my $shard (@SHARDS) {

        l__output($C, qq{\n*** Processing shard=$shard ***\n\n}, 1, 1, 1);

        my $searcher = SLIP_Utils::Solr::create_prod_shard_Searcher_by_alias($C, $shard);
        my $rs = new Result::SLIP();

        my $s;
        my $ok;
        my $id_ct = 0;
        my $start = 0;

        # zero is reserved for the coll_id field for items that are not in
        # any collection. Limit to one coll_id for -C option
        my $item_query = $COLL_ID
          ? qq{q=coll_id:$COLL_ID&start=0&rows=0&fl=coll_id,id}
            : qq{q=coll_id:[1 TO *]&start=0&rows=0&fl=coll_id,id};

        $rs = __handle_query($C, $item_query, $searcher, $rs);
        my $num_found = $rs->get_num_found();
        l__output($C, qq{Solr (shard=$shard) has $num_found items in collections (or in -C COLL_ID)\n}, 1, 1, 1);

        my ($_ok, $large_coll_id_arr_ref) = SharedQueue::get_large_coll_coll_ids($C, $DBH);
        __handle_rc($_ok ? $SLIP_Utils::States::RC_OK : $SLIP_Utils::States::RC_CRITICAL_ERROR,
                    qq{Failed to get large coll_ids\n});

        my %missing_coll_ids = ();
        my %small_coll_ids = ();

        while (1) {

            __exit_STOPSLIP();

            # Get a slice of Solr documents with non-empty coll_id field(s)
            my $query = $COLL_ID
              ? qq{q=coll_id:$COLL_ID&start=$start&rows=$SLICE_SIZE&fl=coll_id,id}
                : qq{q=coll_id:[1 TO *]&start=$start&rows=$SLICE_SIZE&fl=coll_id,id};
            $rs = __handle_query($C, $query, $searcher, $rs);

            my $rows_returned = $rs->get_rows_returned();
            last if ($rows_returned == 0);
            $start += $SLICE_SIZE;
            l__output($C, qq{.$rows_returned ids.}, 1, 0, 0);
            # sleep 1;

            # Parse and return optimized list of ids to test
            my ($id_hashref_of_coll_id_arr_ref, $small_ids_to_enqueue_arr_ref, $missing_ids_to_enqueue_arr_ref)
              = __parse_result_docs(
                                    $C, $rs, $large_coll_id_arr_ref,
                                    \%missing_coll_ids,
                                    \%small_coll_ids
                                   );

            my $num_ids_missing = scalar(@$missing_ids_to_enqueue_arr_ref);
            $num_ids_from_missing_coll_ids += $num_ids_missing;
            l__output($C, qq{\nSolr now has $num_ids_from_missing_coll_ids ids in MISSING MySQL coll_ids\n}, 1, 1, 1)
              if ($num_ids_from_missing_coll_ids);

            if ($num_ids_missing) {
                unless ($NOOP) {
                    l__output($C, "\n\t--> queue $num_ids_missing ids\n", 1, 1, 1);
                    $ok = SharedQueue::enqueue_item_ids($C, $DBH, $missing_ids_to_enqueue_arr_ref);
                    __handle_rc($ok ? $SLIP_Utils::States::RC_OK : $SLIP_Utils::States::RC_CRITICAL_ERROR,
                                qq{Failed to enqueue ids from missing optimize step\n});
                }
            }

            my $num_ids_small = scalar(@$small_ids_to_enqueue_arr_ref);
            $num_ids_from_small_coll_ids += $num_ids_small;
            l__output($C, qq{\nSolr now has $num_ids_from_small_coll_ids ids in SMALL MySQL coll_ids\n}, 1, 1, 1 )
              if ($num_ids_from_small_coll_ids);

            if ($num_ids_small) {
                unless ($NOOP) {
                    l__output($C, "\n\t--> queue $num_ids_small ids\n", 1, 1, 1);
                    $ok = SharedQueue::enqueue_item_ids($C, $DBH, $small_ids_to_enqueue_arr_ref);
                    __handle_rc($ok ? $SLIP_Utils::States::RC_OK : $SLIP_Utils::States::RC_CRITICAL_ERROR,
                                qq{Failed to enqueue ids from small optimize step\n});
                }
            }

            $small_ids_to_enqueue_arr_ref = [];
            $missing_ids_to_enqueue_arr_ref = [];

            foreach my $id (keys %$id_hashref_of_coll_id_arr_ref) {
                my $ids_to_enqueue_arr_ref = [];

                my $coll_id_arr_ref = $id_hashref_of_coll_id_arr_ref->{$id};

                $id_ct++;

                l__output($C, qq{($id_ct)}, 1, 0, 0) if (($id_ct % 100) == 0);

                # Check that this id is in each of these coll_ids
                foreach my $coll_id (@$coll_id_arr_ref) {
                    unless ($CO->one_or_more_items_in_coll($coll_id, [$id])) {
                        $s = $NOOP ? '' : "\n\t--> queue id (unless already in queue)";
                        l__output($C, qq{\n\tid NOT IN MySQL COLLECTION: id=$id, coll_id=$coll_id $s\n}, 1, 0, 1);

                        push(@$ids_to_enqueue_arr_ref, $id);
                    }
                }
                unless ($NOOP) {
                    if (scalar(@$ids_to_enqueue_arr_ref)) {
                        $ok = SharedQueue::enqueue_item_ids($C, $DBH, $ids_to_enqueue_arr_ref);
                        __handle_rc($ok ? $SLIP_Utils::States::RC_OK : $SLIP_Utils::States::RC_CRITICAL_ERROR,
                                    qq{Failed to enqueue ids not in collection\n});
                    }
                }
            }
        }

        my $total_ids_queued = SharedQueue::count_shared_queue_ids($C, $DBH) - $initial_shared_queue_ct;
        my $total_ids_processed = $id_ct + $num_ids_from_missing_coll_ids + $num_ids_from_small_coll_ids;

        $total_ids_queued_over_shards += $total_ids_queued;
        $total_ids_processed_over_shards += $total_ids_processed;
    }

    my $s = $NOOP ? '' : "$total_ids_queued_over_shards added to shared queue";
    l__output($C, qq{\n\nPhase II processed $total_ids_processed_over_shards id occurrences in colls (or in -C COLL_ID)\n\thad $num_ids_from_missing_coll_ids in Solr not in any coll (or not in -C COLL_ID) in MySQL\n\thad $num_ids_from_small_coll_ids in small MySQL colls\n\t$s\n\n}, 1, 1, 1);

    my $phase_2_elapsed = time() - $phase_2_start;
    my $elapsed_min = sprintf("%.2f", $phase_2_elapsed/60);
    my $ss = qq{\nelapsed minutes=$elapsed_min\n};
    l__output($C, $ss, 1, 1, 1);
}

# ---------------------------------------------------------------------

=item l__output

Description

=cut

# ---------------------------------------------------------------------
sub l__output {
    my ($C, $msg, $print_msg, $buffer_msg, $log_msg) = @_;

    Log_sync_i($C, $RUN, $msg) if ($log_msg);
    $MESSAGE_BUFFER .= $msg if ($buffer_msg);
    print STDOUT qq{$msg} if ($print_msg);
}

1;


=head1 AUTHOR

Phillip Farber, University of Michigan, pfarber@umich.edu

=head1 COPYRIGHT

Copyright 2011-2015 Â©, The Regents of The University of Michigan, All Rights Reserved

Permission is hereby granted, free of charge, to any person obtaining
a copy of this software and associated documentation files (the
"Software"), to deal in the Software without restriction, including
without limitation the rights to use, copy, modify, merge, publish,
distribute, sublicense, and/or sell copies of the Software, and to
permit persons to whom the Software is furnished to do so, subject
to the following conditions:

The above copyright notice and this permission notice shall be
included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY
CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE
SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

=cut



